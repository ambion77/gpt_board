import cron from 'node-cron';
import axios from 'axios';
import * as cheerio from 'cheerio';
import db from "../db.js"; // MySQL ì—°ê²° íŒŒì¼
import loadQueries from "../queryLoader.js"; // XML ê¸°ë°˜ ì¿¼ë¦¬ ë¡œë”

let queries = {};

// ğŸ”¹ XML ì¿¼ë¦¬ ë¡œë“œ (ë¹„ë™ê¸°)
(async () => {
  queries = await loadQueries();
})();

// í¬ë¡¤ë§ í•¨ìˆ˜
async function crawlQuotes() {
    try {
        console.log('=== Starting daily news crawling job ===');
        const { data } = await axios.get("https://www.yna.co.kr/rss/news.xml");
        const $ = cheerio.load(data, { xmlMode: true });
        const news = [];

        // RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ ì•„ì´í…œ íŒŒì‹±
        $('item').slice(0, 10).each((_, el) => {
            const $el = $(el);
            news.push({
                title: $el.find('title').text().replace(/\<\!\[CDATA\[(.*?)\]\]\>/g, '$1').trim(),
                link: $el.find('link').text().trim(),
                pub_date: new Date($el.find('pubDate').text()),
                crawled_at: new Date()
            });
        });

        // ëª¨ë“  ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ìˆœíšŒí•˜ë©´ì„œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        for (const item of news) {
            try {
                console.log(`News title saved: "${item.title}"`);
                console.log(`News link saved: "${item.link}"`);
                console.log(`News pub_date saved: "${item.pub_date}"`);
                console.log(`News crawled_at saved: "${item.crawled_at}"`);
                await db.execute(queries.insertNews, [
                    item.title,
                    item.link,
                    item.pub_date,
                    item.crawled_at
                ]);
            } catch (err) {
                console.error('Error saving news:', err);
                continue;
            }
        }

        console.log(`=== Successfully saved ${quotes.length} quotes to database ===`);
    } catch (error) {
        console.error('Crawling job failed:', error);
    }
}

// ë§¤ì¼ ìì •ì— ì‹¤í–‰ë˜ëŠ” ìŠ¤ì¼€ì¤„ëŸ¬
const scheduleCrawling = () => {
    console.log('=== Crawling scheduler initialized ===');
    // ë§¤ì¼ ìì •(00:00)ì— ì‹¤í–‰
    // ë§¤ì‹œê°(ë§¤ì‹œ 00ë¶„)ì— ì‹¤í–‰
    cron.schedule('0 * * * *', crawlQuotes);
};

export default scheduleCrawling;